{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Jue39IQCpCw",
        "outputId": "90392bbf-4337-4913-87aa-b07898fc7594"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: groq in /usr/local/lib/python3.12/dist-packages (1.0.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq) (4.15.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "pip install groq pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.Complete the installation:"
      ],
      "metadata": {
        "id": "cXzDhx4RQwd7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install groq pandas -q"
      ],
      "metadata": {
        "id": "gi45_LIcC_pD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c1395bf-7299-45a0-f4d2-cded3c399f10"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/138.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m133.1/138.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.3/138.3 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.Create sample CSV data(will simulate real ETL data)"
      ],
      "metadata": {
        "id": "Jxhwk_inQN9-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "    'customer_id': [101, 102, None, 104, 102, 106],\n",
        "    'name': ['Rahul', 'Priya', 'Amit', None, 'Priya', 'Sneha'],\n",
        "    'order_amount': [500, 1200, 300, 99999, 1200, None],\n",
        "    'city': ['Mumbai', 'Delhi', 'Mumbai', 'Chennai', 'Delhi', 'Pune']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHP83WSFDkcI",
        "outputId": "41b1e5eb-d46e-4c6a-f710-7ad37f26f46a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   customer_id   name  order_amount     city\n",
            "0        101.0  Rahul         500.0   Mumbai\n",
            "1        102.0  Priya        1200.0    Delhi\n",
            "2          NaN   Amit         300.0   Mumbai\n",
            "3        104.0   None       99999.0  Chennai\n",
            "4        102.0  Priya        1200.0    Delhi\n",
            "5        106.0  Sneha           NaN     Pune\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.Connected with Grok"
      ],
      "metadata": {
        "id": "PbvYHD3oN7hR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from groq import Groq\n",
        "\n",
        "client = Groq(api_key=\"gsk_zBuXT4Xbsdir\")\n",
        "\n",
        "# Test karo\n",
        "response = client.chat.completions.create(\n",
        "    model=\"llama-3.3-70b-versatile\",\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Say hello in one line\"}]\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00yF9nT5D0iA",
        "outputId": "1e3a014f-47e9-4da0-e417-c21316e1e27c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, it's nice to meet you.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.Show the data to AI and get it analysed:"
      ],
      "metadata": {
        "id": "YllhyjKmOpYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_summary = f\"\"\"\n",
        "Dataset has these issues:\n",
        "- Total rows: {len(df)}\n",
        "- Null values: {df.isnull().sum().to_dict()}\n",
        "- Duplicate rows: {df.duplicated().sum()}\n",
        "- Suspicious values: order_amount mein 99999 hai\n",
        "\n",
        "Explain the issues and fix the root cause from a ETL perspective.\n",
        "\"\"\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"llama-3.3-70b-versatile\",\n",
        "    messages=[{\"role\": \"user\", \"content\": data_summary}]\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqfR3MHHEfVk",
        "outputId": "e5c92d46-120d-4630-83a7-19d9bb049eb3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Dataset Issues Explanation**\n",
            "\n",
            "The given dataset has the following issues:\n",
            "\n",
            "1. **Total rows: 6**: The dataset contains 6 rows of data.\n",
            "2. **Null values: {'customer_id': 1, 'name': 1, 'order_amount': 1, 'city': 0}**: \n",
            "   - There is 1 null value in the 'customer_id' column.\n",
            "   - There is 1 null value in the 'name' column.\n",
            "   - There is 1 null value in the 'order_amount' column.\n",
            "   - There are no null values in the 'city' column.\n",
            "3. **Duplicate rows: 1**: There is 1 duplicate row in the dataset.\n",
            "4. **Suspicious values: order_amount mein 99999 hai**: \n",
            "   - There is a suspicious value '99999' in the 'order_amount' column, which could be an outlier or an incorrect value.\n",
            "\n",
            "**ETL Perspective**\n",
            "\n",
            "From an ETL (Extract, Transform, Load) perspective, these issues need to be addressed to ensure data quality and integrity.\n",
            "\n",
            "### Extract\n",
            "\n",
            "During the extract phase, data is collected from various sources. To fix the root cause of the issues:\n",
            "\n",
            "* Verify the data source for 'customer_id', 'name', and 'order_amount' to ensure that the data is being collected correctly and that there are no gaps in the data.\n",
            "* Check the data source for any duplicate data to prevent duplicate rows from being extracted.\n",
            "\n",
            "### Transform\n",
            "\n",
            "During the transform phase, data is cleaned, formatted, and transformed into a suitable format for analysis. To fix the root cause of the issues:\n",
            "\n",
            "* **Handle null values**: \n",
            "  + For 'customer_id' and 'name', either \n",
            "    - Remove the rows with null values if they are not crucial for the analysis.\n",
            "    - Replace null values with a default or mean value if it makes sense for the analysis.\n",
            "    - Use an imputation technique to fill in the null values.\n",
            "  + For 'order_amount', if the null value is due to a missing or incorrect value, consider replacing it with a default or mean value, or use an imputation technique.\n",
            "* **Remove duplicate rows**: \n",
            "  + Use a SQL query or a programming language like Python to remove duplicate rows based on a unique identifier (e.g., 'customer_id').\n",
            "* **Address suspicious values**:\n",
            "  + For the 'order_amount' column, investigate the value '99999' to determine if it is an outlier or an incorrect value.\n",
            "  + If it's an outlier, consider removing it or transforming the data to reduce its impact.\n",
            "  + If it's an incorrect value, correct it or replace it with a default value.\n",
            "\n",
            "### Load\n",
            "\n",
            "During the load phase, the transformed data is loaded into a target system, such as a data warehouse or a database. To fix the root cause of the issues:\n",
            "\n",
            "* Ensure that the loaded data is consistent and accurate.\n",
            "* Use data validation and data quality checks to ensure that the data meets the expected standards.\n",
            "\n",
            "**Example Code (Python)**\n",
            "\n",
            "```python\n",
            "import pandas as pd\n",
            "\n",
            "# Sample dataset\n",
            "data = {\n",
            "    'customer_id': [1, 2, None, 4, 5, 5],\n",
            "    'name': ['John', 'Jane', None, 'Bob', 'Alice', 'Alice'],\n",
            "    'order_amount': [100, 200, None, 400, 500, 500],\n",
            "    'city': ['New York', 'Chicago', 'Los Angeles', 'Houston', 'Seattle', 'Seattle']\n",
            "}\n",
            "\n",
            "df = pd.DataFrame(data)\n",
            "\n",
            "# Print original dataset\n",
            "print(\"Original Dataset:\")\n",
            "print(df)\n",
            "\n",
            "# Handle null values\n",
            "df['customer_id'] = df['customer_id'].fillna(0)  # Replace null with default value\n",
            "df['name'] = df['name'].fillna('Unknown')  # Replace null with default value\n",
            "df['order_amount'] = df['order_amount'].fillna(0)  # Replace null with default value\n",
            "\n",
            "# Remove duplicate rows\n",
            "df = df.drop_duplicates()\n",
            "\n",
            "# Address suspicious values\n",
            "df.loc[df['order_amount'] == 99999, 'order_amount'] = 0  # Replace suspicious value with default value\n",
            "\n",
            "# Print transformed dataset\n",
            "print(\"\\nTransformed Dataset:\")\n",
            "print(df)\n",
            "```\n",
            "\n",
            "Note: This code is for illustration purposes only and may need to be adapted to the specific use case and dataset.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9BGHuPiNFYDX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
